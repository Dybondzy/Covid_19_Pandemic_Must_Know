# Covid_19_Pandemic_Must_Know

## Module 20 Group Project4

### Members of Group 4
1.	Leggett, Michael
2.	Essilfie-Bondzie, Dinah
3.	Teamir rezene, Yodit
4.	Ellerbe, Kimberly
5.	Gross, Jack
6.	Watson, David

### The Groups
Nicholas Bradford (instructor)
Group 1 – Life Expectancy Indicators
1.	Yung, Miaomiao
2.	Doherty, Caelan
3.	Bahloul, Bayan
4.	Lerner, Ryan
5.	lachhab, Mouad

Group 2 – Waste Management (trash collection)
1.	Mangala, Francis
2.	Weber, Yuval
3.	Morakis, Chloe
4.	Wilson, Ashley
5.	Roberts, Truman
6.	Bradshaw, Ryan

Group 3 – Led contaminated water
1.	El-Rashed, Ferris
2.	Erdenebat, Khorolsuren
3.	Akanbi, Olaide
4.	Manning, Sarah
5.	Meneus, Jeffte
6.	Holmes, Monica

Group 4 _ Coronavirus Pandemic Playbook
1.	Leggett, Michael
2.	Essilfie-Bondzie, DINAH
3.	Teamir rezene, Yodit
4.	Ellerbe, Kimberly
5.	Gross, Jack
6.	Watson, David

Group 5 – Bike Sharing
1.	Shane, Thomas
2.	Escamilla, Paola
3.	Koide, Takuma
4.	Tikuye, Habtamu Molla
5.	Manson, Mair
6.	Amegashie, Derrick


# PROJECT PURPOSE 
## Each segment's tasks follow:

### First Segment: 
Sketch It Out: Decide on your overall project, select your question, and build a simple model. You'll connect the model to a fabricated database, using comma-separated values (CSV) or JavaScript Object Notation (JSON) files, to prototype your idea.

### Second Segment: 
Build the Pieces: Train your model and build out the database you'll use for your final presentation.

### Third Segment: 
Plug It In: Connect your final database to your model, continue to train your model, and create your dashboard and presentation.

### Fourth Segment: 
Put It All Together: Put the final touches on your model, database, and dashboard. Lastly, create and deliver your final presentation to your class.

Many aspects you've encountered during this course are integrated into this final project. For instance, Python will be used to clean, prepare, and explore the data, as well as to complete initial analysis. Python libraries, JavaScript libraries (such as Data-Driven Documents, or D3, and Plotly), and Tableau can be used to create visuals to help tell your data story.

Use database integration (Postgres, MongoDB, or SQLite) to store your cleaned data. Also, implement machine learning to enhance your topic. Your work will need a showcase—use tools such as Tableau or JavaScript to build a dashboard to present your results. Finally, prepare and deliver a presentation that walks your class through your project, step by step.

To close, you'll write a short personal reflection after submitting your final project. This reflection provides you time and space to consider the experience, discuss team dynamics, and think about how you would describe the project to an interviewer.

Each segment and the closing self-assessment will be graded. The grading breakdown follows:

### Graded Unit	
Group or Individual?	Points Available	Percentage of Final Score
Segment 1: Sketch It Out	Group	100	19%
Segment 2: Build the Pieces	Group	100	19%
Segment 3: Plug It In	Group	100	19%
Segment 4: Put It All Together	Group	100	40%
Individual Self-Assessment	Individual	10	3%

### Presentation 
(25 points)
The presentation itself is worth 25 points, or a full quarter of your grade for the final segment. This is your chance to share a polished, interview or boardroom ready deliverable.

### Content
The presentation should tell a cohesive story about the project and include the following:

### Selected topic
Reason the topic was selected
Description of the source of data
Questions the team hopes to answer with the data
Description of the data exploration phase of the project
Description of the analysis phase of the project
Technologies, languages, tools, and algorithms used throughout the project
Result of analysis
Recommendation for future analysis
Anything the team would have done differently

### Slides
The presentation should be finalized in Google Slides and include the following:

Slides are primarily images or graphics (rather than primarily text).
Images are clear, in high-definition, and directly illustrative of subject matter.
Live Presentation
Requirements for the live presentation follow:

All team members present in equal proportions.
The team demonstrates the dashboard's real-time interactivity.
The presentation falls within any time limits provided by the instructor.
The submission includes speaker notes, flashcards, or a video of the presentation rehearsal.

### GitHub Repository 
(10 points)
Your final segment deliverable also will include a link to your GitHub repository. Of course, since you'll be contributing to this repository over time, you'll also see repository requirements in the rubrics for the other three segments.

### Main Branch
All code in the main branch should be production-ready. All code should be clean, commented, easy to read, and adhere to a coding standard, such as PEP8.

The main branch should include:

All code necessary to perform exploratory analysis
All code necessary to complete the machine learning portion of the project
Any images that have been created (at least three)
Requirements.txt file
README.md

### README.md should include:

Cohesive, structured outline of the project (this may include images, but they should be easy to follow and digest)
Link to dashboard (or link to video of dashboard demonstration)
Link to Google Slides presentation
IMPORTANT
The descriptions and explanations required in all other project deliverables should also be in your README.md as part of your outline, unless otherwise noted.

### Individual Branches
Requirements for the individual branches follow:

At least one branch for each team member
Each team member has at least four commits for the duration of the final segment (16 total commits per person)
Machine Learning Model (25 points)
In your first segment, you'll create a model mockup, importing data in the desired format and exporting data in the required format. In your second and third segments, you'll train your model and confirm it's working with your robust database. For the final segment, you'll submit your machine learning model, the description and working code, as well as the following information:

Description of data preprocessing
Description of feature engineering and the feature selection, including the team's decision-making process
Description of how data was split into training and testing sets
Explanation of model choice, including limitations and benefits
Explanation of changes in model choice (if changes occurred between the Segment 2 and Segment 3 deliverables)
Description of how the model was trained (or retrained if the team used an existing model)
Description and explanation of model's confusion matrix, including final accuracy score
Additionally, the model obviously addresses the question or problem the team is solving.

If statistical analysis is not included as part of the current analysis, the team should add a description of how it would be included in the next phases of the project.

### Database Integration 
(25 points)
Just as you did for the machine learning model, you'll create a mockup or "dummy" database during the first segment of your project to make sure the model works. This mockup will follow the format of the expected database, but it will be simpler and likely in a CSV or JSON format.

For your final segment, you'll present a project with a fully integrated database, with the following features:

Stores static data for use during the project
Interfaces with the project in some format (e.g., scraping updates the database, or database connects to the model)
Includes at least two tables (or collections if using MongoDB)
Includes at least one join using the database language (not including any joins in Pandas)
Includes at least one connection string (using SQLAlchemy or PyMongo)
IMPORTANT
If you use a SQL database, you must provide your Entity Relationship Diagram (ERD) with relationships.

### Dashboard 
(15 points)
You'll demonstrate your dashboard during the presentation, but it is important enough to count as its own aspect of the deliverable. When building your dashboard, keep the following requirements in mind:

The dashboard presents a data story that is logical and easy to follow for someone unfamiliar with the topic. It should include all of the following:

Images from the initial analysis
Data (images or report) from the machine learning task
At least one interactive element
Either the dashboard is published or the submission includes a screen capture video of it in action.

### View the Full Rubric
You can download the full rubric and save it to your desktop. Review it regularly to make sure you're on track.

Rubric for the entire Final Project (Links to an external site.)
Now that you have an idea of what that final deliverable at the end of the fourth segment will look like, let's talk a little bit about how your team will work together to get it done.

# 1st Segment Ruberic
The final rubric covers points you'll be working on each week. The project overview covered these too, and you can find them in the assignment details for the fourth segment deliverable as well.

If you look closely, you'll notice that the deliverable requirements for this first segment fall into the same categories in the final rubric: Presentation, GitHub Repository, Machine Learning Model, Database Integration, and Dashboard.

Of course, the level of sophistication required for the First Segment deliverable will be much lower than that for the Fourth Segment deliverable. Also, you'll notice that some segments have more points in one category, and fewer in another, than the next segment. That's because the project builds over time, and while the intensive work may shift from one week to the next, it's critical to keep the big picture in mind.

Take a moment to read through the mastery requirements for the first segment.

#### Presentation 
(30 points)
Content
The team members have drafted their project, including the following:

Selected topic
Reason they selected the topic
Description of the source of data
Questions they hope to answer with the data
IMPORTANT
The content does not yet need to be in the form of a presentation. It can be text in the README.md.

#### GitHub Repository 
(10 points)
Main Branch
The main branch should include:

README.md

#### README.md
The README.md should include:

Description of the communication protocols
Individual Branches
Requirements for the individual branches follow:

At least one branch for each team member
Each team member has at least four commits for the duration of the first segment
Machine Learning Model (35 points)
Team members will be expected to present a provisional machine learning model that stands in for the final machine learning model and accomplishes the following:

Takes in data from the provisional database
Outputs label for input data
Database Integration (25 points)
Team members will be expected to present a provisional database that stands in for the final database and accomplishes the following:

Sample data that mimics the expected final database structure or schema
Draft machine learning model is connected to the provisional database
Dashboard (0 points)
There are no deliverables associated with the dashboard for this segment.


# Work Definition
## What You Will Accomplish
By the end of this module, you will have created the foundation for your final project. By defining roles between your team members and establishing a communication structure beforehand, you'll already be off to a great start. Additionally, you'll complete the following tasks:

Decide on a topic for the project—think of a question that can be answered using data.
Create a repository for the project and invite the other team members to join.
Source a dataset that will suit your needs (you can even use multiple datasets if applicable).
Begin to clean, organize, and perform exploratory data analysis on your datasets so that they're ready for analysis.
Include mockups of a machine learning model and a database.
Plan Your Schedule
Project weeks can be intense. Make sure to pad your tasks with extra time. There's an excellent chance you'll find yourself researching issues you've not encountered before, or that you'll want your code to do something more advanced than what has been covered in class. That's all OK!

# Deliverable 1 Foundation
Before jumping into your project work, you'll need to create a solid foundation to build upon. This means familiarizing yourself with your role and responsibilities for the week. Additionally, you'll need to establish communication strategies and prepare a repository. You'll create a mockup of a machine learning model for the virtual class, as well as a mockup of a database with sample data, or even fabricated data. This way, you'll have a firmer grasp of how you want these different pieces to interact.

By this week's virtual class, your team will need to come up with a question that can be answered with data, and you'll need to source the data you intend to use. During this segment's live session, your team will meet with your instructor to talk about your project topic—listen to the feedback before moving on to the next segment. By the end of the meeting, you'll know what you'll be working on for the remainder of the course.

Completing an exploratory data analysis will help you determine if your topic is viable or if further consideration (or even a different topic) is needed. It'll also help you prepare for that conversation with your instructor. It's a good idea to think about what metrics you'll be including in the machine learning portion.

Before meeting with your instructor, your team will need to complete the following:

Decide on a topic, source data, and perform exploratory data analysis.
Create a repository and establish individual branches for each team member.
Create a mockup of a machine learning model.
Create a mockup of a database.
! https://covidtracking.com/data/download

Decide which technologies will be used.
Work as a Team
Once a topic has been agreed upon, each member will be assigned a role, indicated by a particular shape: square, triangle, circle, and X. Each shape, or role, will have an assigned task.

### X role --- Jack, Yodi
The X role is mandatory for teams of four and optional for teams of three. Later, we'll cover how the designations will work. For now, review the following deliverable requirements for the first segment:

X: The member in the X role will decide which technologies will be used for each step of the project.

### Square --- David
Square: The team member in the square role will be responsible for the repository.

### Triangle --- Michael
Triangle: The member in the triangle role will create a mockup of a machine learning model. This can even be a diagram that explains how it will work concurrently with the rest of the project steps.

### Circle --- Kimi, Dinah
Circle: The member in the circle role will create a mockup of a database with a set of sample data, or even fabricated data. This will ensure the database will work seamlessly with the rest of the project.

1. The team member in the circle role is in charge of the mockup database. 
2.This means you're using a SQL-based database, including an ERD of the database and a document pointing out how it is integrated into your database and how it works with the code. 
3. You'll need to use either sample data or even fabricated data to test it. 
4. When you submit this database for your weekly grade, make sure you're submitting the data used for testing as well. 
5. Make sure to upload it to the repository along with the rest of the database-related work.
6. By the date of your virtual class, you're required to submit the mockup database to your instructional staff. 
7. This is a great opportunity to test out your new GitHub branch. It's just as easy to share a link to a branch as it is to share a link to a repository.
8. Once you're set up in your repository and using your branch, create a document describing the schema of the database (this can be a markdown document, or an ERD). 
9. Push the document up to the repository, then open a webpage to GitHub.



# First Segment: 
# Coronavirus Pandemic Playbook
## Project Topic and Description

Topic
Investigating the six most important factors that led to the spread of COVID-19 cases in states across the United States.

Gender
Age
Weight
Race
Political Party
Religious Affiliation
Income Level
Population Density
Audience
The National Governors Association has tasked our group, the COVID-19 Rapid Response Group: Preparing for the Next Pandemic will be presenting our pandemic playbook to at a COVID-19 response conference with the National Governors Association and to the United States Conference of Mayors. The two nonpartisan organizations comprised of governors from the U.S.'s 55 states and territories and mayors of U.S. cities with population of 30,000 or more. Typically these groups meet separately to share strategies across their jurisdictions, however, this conference is a rare opportunity for all executives to gather and learn how to better respond to the next pandemic and minimize the spread, deaths, and economic impact.

Why Should We Care?
As a capitalist society, some economic measures of success for the U.S. are jobs created and GDP growth. The COVID-19 brought the deepest recession since the end of WWII as the global economy shrunk by 3.5% and 114 million people lost their jobs in 2020. The impact of this shock is likely to be felt for years to come.

The Brookings Institute identified state capacity as one of three pre-existing conditions that amplified the impact of the shock. The COVID-19 crisis posed a critical challenge for policymakers as they needed to quickly reach workers and households during the abrupt economic crisis. There is evidence that if states were more prepared to handle a pandemic, economic performance would not have suffered as it did in 2020. Our nation's governors and mayors have the opportunity to learn where our countries weak points are that led to these incredible economic losses and mitigate them in a future pandemic.

### Data Sources for Project
[John Hopkins Coronavirus Data](https://coronavirus.jhu.edu/data/new-cases-50-states)

[U.S. Census Data](https://www.census.gov/data/developers/data-sets.html)

[Additional data source that we are considering](https://docs.google.com/document/d/10i01u6oQAUVCbk5VTL6G0rIsTF9JlO1I90XTCDXWTCA/edit)

[Another possible data APIs](https://blogs.mulesoft.com/dev-guides/track-covid-19/)

[A database that we can consider] (https://covidtracking.com/data/download)

(https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-Profile/xigx-wn5e)
https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4

https://worldpopulationreview.com/states/state-abbreviations (for states)

### Questions to Investigate During Project

1. What is the population per state at the beginning and end of the pandemic?
2. How has race played a role in the spread of the COVID-19 pandemic?
3. Could the level of poverty and inequality affect the spread of COVID-19? If so what is the impact?
4. Did having medical insurance play a role in the cure and deaths?
5. What were the top 5 MSAs (Metropolitan Statistical Areas) impacted by Covid-19? (Def: MSA is a geographical region with a relatively high population density at its core and close economic ties throughout the area.)
6. What were the top 20 uSAs (Micropolitan Statistical Areas) impacted by Covid-19?
7. During periods of Covid-19 case spikes, were there geographical or state areas that trended with these spikes?
8. Did political affiliation of areas have an influence on the number of Covid cases prior to vaccine distribution?
 
### Machine Learning
The machine learning model should answer:
Which model did you choose and why?
How are you training your model?
What is the model's accuracy?
How does this model work?

The inputs for the model will be covid cases by state, gender, age, weight, race, political party, religious affiliation, income level, and population density. 
We are using a multiple linear regression model because we have multiple explanatory variables 
(the independent variables which are the earlier identified factors) and we want to know how strong the relationship is between these independent variables with our dependent variable, which is covid cases. 
We are using a linear model as opposed to a logisitical model because our dependent variable is continuous. 
We will run the model with the hopes of identifying the largest factors that played a role in the spread of covid-19. 
We will be considering the R squared value and the standardized coefficient when running our model in order to consider if the model is well fitted and compare the factors to see which play a larger role. 
The sample equation that we are using to build the model is below:

yi=β0+β1xi,1+β2xi,2+…+βkxi,k+ϵi.

From an early perspectivce we have identified:

yi = dependent variable—the number of COVID-19 cases

xi1 = explanatory variable-the number of men and women

xi2 = religion

xi3 = race

xi4 = political party affiliation

xi5 = income level

xi6 = health care professionals/doctors registered by state


What is the model's accuracy?


### Communication Protocol 

We are utilizing the available and most suitable resources as our communication tools. Zoom and Slack. We are aiming to meet twice a week in addition to meeting and discussing over the regular virtual class hours. 
We have created a group and direct messages for group members in Slack, and we may use this channel for any cases of emergency. 

### Technologies Used

#### Database storage

We will use SQL database tool to extract, organize and retrieve our data.

#### Data Cleaning and Analysis
Pandas will be used to clean and transform the data and perform an exploratory analysis. 

#### Dashboard

We will create an HTML/CSS portfolio to showcase our project and Bootstrap components to polish and customize the portfolio. We will also use JavaScript functions to display dynamic and interactive dashboard. 

#### Machine Learning 

During this segment, the team will continue to work on their analysis of the data. Make sure to really explore what the data has to offer and continue to refine how machine learning will help solve the question or provide an enhancement to the project. This means moving from a preliminary model into your machine learning model. The mockup database created last week will need to be integrated and refined as well, and the visuals that help tell the data story will need to be created.


## 2nd Segment Ruberic
The final rubric covers points you'll be working on each week. The project overview covered these too, and you can find them in the assignment details for the fourth segment 

Let's take a look at how these assignments are distributed across the roles:

### Team: 
Continue with analysis: add, commit, push, create new branches as needed, and utilize GitHub's built-in tools, such as PRs, to review the work you and your teammates have completed (this is an ongoing process, so keep it up!).

### Square: 
Refine the machine learning model you'll be using (train and test).
Triangle: Transform the mockup database into a full database that integrates with your work.

### Circle: 
Continue with analysis and create visuals to accompany the data story.

### X: 
Outline and begin work on a dashboard to house your final project. Check and test the work completed against the rubric.

### Second Segment Rubric

Presentation (15 points)
Content
The presentation outlines the project, including the following:

Selected topic
Reason topic was selected
Description of the source of data
Questions the team hopes to answer with the data
Description of the data exploration phase of the project
Description of the analysis phase of the project

Slides/Github
Presentations are drafted in Google Slides.
Updated README file

GitHub Repository (10 points)
Main Branch
All code in the main branch is production-ready.

The main branch should include:

All code necessary to perform exploratory analysis
Some code necessary to complete the machine learning portion of project
README.md
README.md should include:

Description of the communication protocols
Outline of the project (this may include images, but they should be easy to follow and digest)
Individual Branches
Requirements for the individual branches follow:

At least one branch for each team member
Each team member has at least four commits for the duration of the second segment (eight total commits per person)
Machine Learning Model (30 points)
The team members are expected to submit the code for the machine learning model, as well as the following:

Description of preliminary data preprocessing
Description of preliminary feature engineering and preliminary feature selection, including the decision-making process
Description of how data was split into training and testing sets
Explanation of model choice, including limitations and benefits
Database Integration (30 points)
The team members are expected to present a fully integrated database, including the following:

Database stores static data for use during the project
Database interfaces with the project in some format (e.g., scraping updates the database)
Includes at least two tables (or collections, if using MongoDB)
Includes at least one join using the database language (not including any joins in Pandas)
Includes at least one connection string (using SQLAlchemy or PyMongo)
IMPORTANT
If you use a SQL database, you must provide your ERD with relationships.

Dashboard (15 points)
A blueprint for the dashboard is created and includes all of the following:

Storyboard on a Google Slide(s)
Description of the tool(s) that will be used to create the final dashboard
Description of interactive element(s)

### Square
During the second segment, the square will focus on the machine learning model. Building off of the preliminary model built in the first segment, continue to refine, train, and test the model. Make sure to document how it ties into the project. There needs to be a description of the model as well as any preprocessing that was involved. Additionally, capture an interpretation of how accurate, precise, or sensitive the model is.

One question: If you had more time, where would you like to investigate for finer tuning? Keep this in mind as the presentation is being put together since it could be a really strong talking point.

For this segment, continue using the same branch that was created during the last segment. If that branch has already been merged in, that's OK. You can just create a new one to work from instead.

There are several questions to keep in mind as you work through this segment:

How does it work?
Why this specific model?
What is the model's accuracy?
If there are statistics involved, what stats are being included in analysis and why?
If no statistics are involved, what would you include if you had more time?
There's a chance you'll run into stumbling blocks here or there, too. Remind yourself that it's OK and not to get stuck—instead of spending vast amounts of time stuck on a single problem, document it, then (during the presentation) discuss how you would approach it differently if you had more time.

At the end of this segment, you will need to have a description of the model and a discussion about any preprocessing involved. Additionally, an interpretation of how accurate, precise, and sensitive the model is should be included for the submission.


### Triangle

The team member in the triangle role is involved in upscaling the project's database. Last segment, a mockup database was created using either sample or fabricated data. Now we need to level it up to use the full static dataset that was sourced earlier. It's a good idea to create a new branch to work from for this task, to help track different versions the project will progress through.

Now let's take a closer look at the different database deliverables for this segment.

First, make sure the database is integrated fully and that it interfaces with the project in some form. For example, does web scraping add or update data? The same thought can be applied to the application programming interface (API) calls as well.

Next, there should be at least two tables (or collections if Mongo is being used) in the database. If you're collecting data on plants and their common locations, for example, you would have a table for the plant's information (genus, species, brief description) and a second table for geographic locations.

Additionally, there should be at least one join completed within the database. Using the same example from earlier, the two tables could be joined to show all of the plants' information and the locations.

Finally, there will need to be at least one connection string included. For example, if you're using PyMongo, you'll need to include a connection string in Python that demonstrates the link between your code and the database.

### Circle
The team member in the circle role will continue to refine the analysis. This includes generating at least three images to use in the presentation and with the dashboard. Imagine that the presentation, and the dashboard, are being shown to a potential employer. Not only do the images need to be neat and clean, but they also need to clearly add weight to the data story being told.

A good way to increase the quality of your images is to incorporate a visualization library, such as Seaborn if you're using Python, to make high-quality PNGs that can be reused as needed.

Create a new GitHub branch to work from during this segment. This is a great way to get feedback from your team on the visuals you create—they will be able to see them and provide feedback (and encouragement!) as you create them and experiment with different color themes.

It's important to keep in mind that the dashboard will require interactivity; so if you're creating maps using GeoJSON, this is a great time to make sure some fancy things are included, such as layers and filters.

### X
The team member in the X role will focus on the team's dashboard. Create a storyboard of a dashboard that will be used to display your data findings. Imagine that you and your team will be presenting this dashboard to a potential employer.

A potential employer may not be familiar with the dataset you've been working with. Or they may not have seen the specific technology you've used to create the dashboard first-hand. Even if they have, you want to create a dashboard that is easy to understand for everyone.

It will also need to include interaction—something more sophisticated than a tooltip. A map with multiple layers, for example, is a powerful tool. Or an interactive chart that can be filtered or has adjustable zoom can lend great strength to analysis. This is something to keep in mind and collaborate on with whomever is in the circle role during this segment.


Module 20 Second Segment Project Deliverable

Two segments down, and two to go! Congrats on making it to the halfway point in this final project.

IMPORTANT
Remember that every member of the team, regardless of his or her role, will need to submit all of the deliverables for each segment.

Be sure to carefully review any feedback your instructor may give you on your work, as that feedback will help you improve and correct course, if need be.

Rubric
Now that you’re ready to submit, make sure that you have all the deliverables in place by reviewing the rubric one final time.

### Segment 2 Deliverable

# Coronavirus Pandemic Playbook

## Project Topic, Background, Audience

The term 'pandemic playbook' circulated in the news during the beginning of the COVID-19 pandemic. U.S. President Barack Obama's team had outlined how to respond to infectious diseases and biological incidents so future administrations would be prepared to respond to the next pandemic or biological threat. While the federal government prepared guidelines, state governments from the 50 states + DC were woefully unprepared for a pandemic. The COVID-19 pandemic brought the [deepest recession since the end of WWII](https://www.brookings.edu/research/social-and-economic-impact-of-covid-19/) as the global economy shrunk by 3.5% and [114 million](https://www.weforum.org/agenda/2021/02/covid-employment-global-job-loss/) people lost their jobs in 2020. The impact of this shock is likely to be felt for years to come.

The National Governors Association, a nonpartisan organizations comprised of governors in the U.S., tasked with creating an updated playbook for state governments. They have asked us to provide a comprehensive review of factors that led to the spread of COVID-19 cases in states across the United States. We will be presenting our at the next National Governors Association annual conference in late 2021.

### Project Goal
Drawing on data from CDC, U.S. Census, and many other sources, our goal is to determine which social, economic, and political factors contributed to the spread of COVID-19. There is evidence that if states were more prepared to handle a pandemic, economic performance would not have suffered as it did in 2020. Our nation's governors have the opportunity to learn where our state's weak points were that led to these incredible economic losses and mitigate them in a future pandemic. Our team is confident that our machine learning algorithm will predict which factors contributed the most to the spread of respiratory diseases like COVID-19. The information will valuable for state lawmakers' future economic and social political decisions.

### Project Factors 

Given our audience for the project, the data we've obtained for each factor will be organized by state. 

**Target Variable**
* Number of COVID-19 Cases / State Population

**Social Factors**
* Sex
* Age
* Race
* Religion

**Geographical Factors**
* Population Density
* Number of Commercial Airports / State Land Area

**Economic Factors**
* Median Household Income

**Political Factors**
* State Mandates / COVID-19 rules
* Political Leaning

**Lifestyle Factors**
* Health Insurance Coverage 
* Exercise Frequency
* Social Inclusivity 
* Work Life Status
* Monetary Stability

### Questions to Investigate During Project
1. Which social, economic, geographical, lifestyle or political factors contributed the most the spread of the disease?
2. Which category of factor contributed the most the spread of the disease?
3. Is there a connection between state policy or political leaning (i.e. mask mandate) and the spread of COVID-19 within the state
4. Do we need to account for the size of the population that didn't have COVID-19 when using a machine learning model?

## Data Exploration and Analysis Phases

### Data Exploration and Analysis Overview

We began the project by looking at the entirety of COVID-19 CDC data, which consists of 27 million rows and 19 columns of unique patient information. We quickly realized that if we wanted to replicate the spread of COVID-19 based on any factor, we needed to account for the population that didn't have the disease. We established **Number of COVID-19 Cases / State Population** as our target variable. We found ratio would be easier to handle data-wise than working with large population datasets or creating pseudo population data. Next, we moved on to categorical factors. 

For social factors, we looked at U.S. Census data estimates for information on sex, age, and race. We observed that both datasets had either state abbreviations or states spelled out with their full names. We knew we could join data tables by state, so we focused our efforts on finding geographical, economic, lifestyle and political factors with state columns already available.

### Datasets and Sources

* [COVID-19 Cases by Age, Sex, Race](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv) Source: U.S. Census and CDC
* [U.S. Commercial Airports by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/Group4%20Airport%20By%20Area.csv) Source: FAA
* [State Mask Mandate Policy/Political Affiliation by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/state_factors_from_gallup.csv) Source: Gallup
* [Median Household Income by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/household_income_by_state.csv) Source: U.S. Census

### Description of Data Sources

As stated in the Data Exploration subheading, our original dataset consisted of over 27 million rows of unique patient Covid-19 data sourced from the Center for Disease Control and Prevention (CDC) Case Surveillance Public Use Data. Having analyzed the quality of our data, the Team pivoted to finding additional, specific data that would support our model, have minimum missing data and null values and to answer our investigaative questions with a unique perspective. Our primary and final dataset will be constructed by merging primary demographic information from the Center of Disease Control & Prevention (CDC), US census data from US Census Bureau and qualitative survey data from Gallup that will consist of 50 rows of State values and 50-55 columns of factors.  

## Database

### Database Schema ERD

![CORONAVIRUS_PANDEMIC_PLAYBOOK_wCENSUSdata_ERD](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Images/CORONAVIRUS_PANDEMIC_PLAYBOOK_wCENSUSdata_ERD.png)

### Building the Database

[Database Storing Overview](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/Project%204%20Database%20SQL.txt)

**Steps**

1. We chose input data from CDC from March - December 2020 because March marked when the U.S. declared a state of emergency and December was when the first COVID-19 vaccine dose was administered and U.S. Census data. After storing the data in pgAdmin - PostgreSQL, we selected age group, state, sex, and race, columns from both datasets.
2. We then created a table to hold the input data from CDC and U.S. Census. We called the table CDC_INPUTDB_CLEANED
3. We identified the age group options available in the data and created an age group table
4. We inserted the age group table into the CDC_INPUTDB_CLEANED table
5. We repeated steps 3 and 4 for sex and race factors
6. We read the query to summarize counts and selected Maryland as our test state for our new table
7. Before creating the final table that include counts for the segments of each factor, we summarized each column's datatype.
8. We created our final table to hold the total value counts: COVID_MARCH2020_DEC2020_PROJECT4
9. Then we added up the counts for the segments of each factor and inserted into the COVID_MARCH2020_DEC2020_PROJECT4 table
10. Exported to [COVID-19 Cases by Age, Sex, Race](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv)

### Data Dictionary

![image](https://user-images.githubusercontent.com/79073778/126088189-b23583d2-390d-4510-8e2c-d58fafbd54d2.png)

## ETL Method

### Extracting the Data
Our main dataset was COVID-19 CDC data, which consists of unique patient information spanning 19 columns and 27 million rows. With such a large dataset, we used Amazon S3 to store the data and used Google Colab with Pyspark to access and load the data.

### Transforming the Data
With the data loaded, we could now transform our data. We first filtered the data to be between March 2020 and December 2020. We chose this date range because March 2020 was when the United States declared COVID-19 a pandemic and December 2020 was when the first vaccine was administered in the United States. After filtering the data by date, we dropped many columns from the dataset for either or both of these reasons: 1) there were too many missing values for the variable to be usable and/or 2) the variable was not useful for our analysis. After dropping the unnecessary columns, the data was left with four variables: res_state, age_group, sex, and race. The dataset also had missing values which were identified in the data as either "Missing", "Unknown", or "NA". We replaced all the "Missing" and "Unknown" values to be "NA" for simplicity in identifying the missing values. The data was then exported to a CSV file where it was then imported into SQL for storage and further querying.

### Loading the Data
We used SQL to store the data and query it so that the data would be organized by state with the values becoming our new features. For example, we now have "Male" and "Female" as features of our data with totals of each for each state, whereas in the base CDC data, "sex" was the feature and "Male" and "Female" were values for the unique patients. The other features we are using were imported from their respective CSV files and joined to this main table. Using the U.S. Census data, we were able to create the features for those who do not have COVID by subtracting the number of people with COVID by the total numbers for each state. For example, to find the total number of females who do not have COVID for the state of Maryland, we subtracted the total number of females with COVID from the total population of the state of Maryland.

### Handling Missing Values
Currently, missing values are their own features in our dataset where we have them for age, sex, and gender, which could potentially result in poor performance of the machine learning model. We have a couple other potential ideas on how we could handle the missing values:

- As the features with missing values are categorical variables, we could impute the missing values by using the mode.
- We can predict the missing values for the categorical variables by using a classification model. We would split the data as such:
  - y_train: rows from data with non null values
  - y_test: rows from data with null values
  - X_train: Dataset except data features with non null values
  - X_test: Dataset except data features with null values

## Machine Learning

### Model Choice
The model we chose to use is a **supervised random forest regression model.** We chose supervised machine learning because we have labeled data (our features in tabular form) and outputs. The input data, or our features, has a paired outcome which is plugged in to train the model to predict outcomes. Supervised machine learning models have target variables, or dependent variables, about which we want to gain a deeper understanding. In our case our target variable is how much effect COVID had on a state's population by looking at the total number of COVID cases divided by the total state population.

We chose a random forest algorithm because it can handle many input variables of which we have many. It can also account for null values, which we found many in our base dataset. The algorithm can run efficiently on large datasets, and most importantly, random forest models can be used to rank the importance of input variables. This fits the question we are trying to answer perfectly - **what are the top factors that influence the spread of COVID?** A random forest model will help us rank the most influential factors. Since we have a large dataset with many features, as well as both continuous and categorical non-linear variables, a random forest algorithm will be more efficient and more accurate than a simple linear regression. While a large number of trees in a random forest algorithm can be slow requiring a lot of computational power and resources, the advantages outweigh the disadvantages.

### Code for Random Forest Model
To create the random forest model, we first initialize the dependencies, notably the 'from sklearn.ensemble import RandomForestRegressor'.

```
import pandas as pd
from path import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
```

After loading in the data, we use one hot encoding to account for null values and convert categorical variables to integer data.

```
file_path = ("COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv")
covid_df = pd.read_csv(file_path)

covid_cat = covid_df.dtypes[covid_df.dtypes == "object"].index.tolist()

from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder(sparse=False)
encode_df = pd.DataFrame(enc.fit_transform(covid_df[covid_cat]))

encode_df.columns = enc.get_feature_names(covid_cat)
encode_df.head()
```

We then merge the one hot encoded features to the main dataframe and drop the originals.

```
covid_df = covid_df.merge(encode_df, left_index=True, right_index=True)
covid_df = covid_df.drop(covid_cat,1)
covid_df
```

We split our preprocessed data into our features and target variables.

```
y = covid_df["case_pop"].ravel()
X = covid_df.copy()
X = X.drop("case_pop", axis=1)
```

We then split the data into training and testing sets and scale the data. We set random_state to a number in the testing phase so that we can consistently see the same results when the test model is run (this could possibly be removed for the final model).

```
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

scaler = StandardScaler()

X_scaler = scaler.fit(X_train)

X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)
```

We initialize the random forest classifier and fit the model. We set n_estimators to 128 because best practice is to use between 64 and 128 forests. Generally, the higher the number, the stronger and more stable the predictions are. Given that this is a test model, it is reasonable to assume the model might be able to handle 128 forests.

```
rf_model = RandomForestRegressor(n_estimators=128, random_state=1) 

rf_model = rf_model.fit(X_train_scaled, y_train)
```

We make predictions and then evaluate how well the model classified the data.

```
predictions = rf_model.predict(X_test_scaled)

acc_score = accuracy_score(y_test, predictions)

print(f"Accuracy Score : {acc_score}")
```

We finally rank the importance of the features and see which have the most impact on the output.

```
importances = rf_model.feature_importances_
importances

sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)
```

## Dashboard

### Blueprint and Interactive Elements

One of the interactive elements we are using is the filter action. Filter actions send information between worksheets. Typically, a filter action sends information from a selected mark to another sheet showing related information. Behind the scenes, filter actions send data values from the relevant source fields as filters to the target sheet and dashboards.

For example, in a view showing the states, when a user selects a particular state name, a filter action can show all state values for all the displayed variables. 
User can select marks to see information about a specific data filed. One can also select an individual mark or multiple ones by holding down the Ctrl key (for Windows) or the Command key (macOS).

When you select marks in the view, all other marks are dimmed to draw attention to the selection. The selection is saved with the workbook. Quick data view can also be done by one of the run-on options; hovering your mouse on the charts/marks. 

We have also created a simple HTML file to show the dashboard in a dedicated webpage with another interactive element where users can download the analysis into PDF file. 
 

### [Tableau Dashboard Demo](https://public.tableau.com/views/ALLSTATESDATAMARCHtoDEC2020/Dashboard4?:language=en-US&:display_count=n&:origin=viz_share_link)

## Appendix 

### Roles

* **Project Manager**
    * David
* **Database Storage**
    * Dinah
    * Kimi
    * Michael
* **Data Cleaning and Analysis**
    * Dinah
    * Kimi
    * Michael
* **Machine Learning Model**
    * Michael
* **Presentation of Findings**
    * Yodit (Tableau)
    * Jack (Tableau
    * David (approver) & Team (GitHub)

### Technologies Used

* **Database Storage**
    * pgAdmin - PostgreSQL
    * AWS RDS
* **Data Cleaning and Analysis**
    * Juypter Notebook - Pandas
* **Machine Learning Model**
    * Google Collab Notebook
* **Presentation of Findings**
    * Tableau Public
    * GitHub

### Communication Protocol 

* [Project Checklist](https://docs.google.com/spreadsheets/d/1G9lvPyMrlkjnYT-qGigKpNdVk72A9Zu0Je7hyy8Q6ug/edit?usp=sharing)
* [Group meeting agendas](https://drive.google.com/drive/folders/1sMOLvKQO-S99917fQL9axuocZujgKNZQ?usp=sharing)

We are meeting twice a week outside of class on Zoom and consistently communicating over Slack. David has established best pratices in GitHub, so we don't overwrite each other's work.


sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)
```

## Dashboard

We will create an HTML/CSS portfolio to showcase our project and Bootstrap components to polish and customize the portfolio. We will also use JavaScript functions to display dynamic and interactive dashboard. 

### [Tableau Dashboard Demo](https://public.tableau.com/app/profile/yodit.teamir/viz/MarylandCoviddemo/DemoStory)


---------------------------------------------------------------
## Deliverable 3

# Coronavirus Pandemic Playbook

## Project Topic, Background, Audience

The term 'pandemic playbook' circulated in the news during the beginning of the COVID-19 pandemic. U.S. President Barack Obama's team had outlined how to respond to infectious diseases and biological incidents so future administrations would be prepared to respond to the next pandemic or biological threat. While the federal government prepared guidelines, state governments from the 50 states + DC were woefully unprepared for a pandemic. The COVID-19 pandemic brought the [deepest recession since the end of WWII](https://www.brookings.edu/research/social-and-economic-impact-of-covid-19/) as the global economy shrunk by 3.5% and [114 million](https://www.weforum.org/agenda/2021/02/covid-employment-global-job-loss/) people lost their jobs in 2020. The impact of this shock is likely to be felt for years to come.

The National Governors Association, a nonpartisan organizations comprised of governors in the U.S., tasked with creating an updated playbook for state governments. They have asked us to provide a comprehensive review of factors that led to the spread of COVID-19 cases in states across the United States. We will be presenting our at the next National Governors Association annual conference in late 2021.

### Project Goal
Drawing on data from CDC, U.S. Census, and many other sources, our goal is to determine which social, economic, and political factors contributed to the spread of COVID-19. There is evidence that if states were more prepared to handle a pandemic, economic performance would not have suffered as it did in 2020. Our nation's governors have the opportunity to learn where our state's weak points were that led to these incredible economic losses and mitigate them in a future pandemic. Our team is confident that our machine learning algorithm will predict which factors contributed the most to the spread of respiratory diseases like COVID-19. The information will valuable for state lawmakers' future economic and social political decisions.

### Project Factors 

Given our audience for the project, the data we've obtained for each factor will be organized by state. 

**Target Variable**
* Number of COVID-19 Cases / State Population

**Social Factors**
* Sex
* Age
* Race
* Religion

**Geographical Factors**
* Population Density
* Number of Commercial Airports / State Land Area

**Economic Factors**
* Median Household Income

**Political Factors**
* State Mandates / COVID-19 rules
* Political Leaning

**Lifestyle Factors**
* Health Insurance Coverage 
* Exercise Frequency
* Social Inclusivity 
* Work Life Status
* Monetary Stability

### Questions to Investigate During Project
1. Which social, economic, geographical, lifestyle or political factors contributed the most the spread of the disease?
2. Which category of factor contributed the most the spread of the disease?
3. Is there a connection between state policy or political leaning (i.e. mask mandate) and the spread of COVID-19 within the state
4. Do we need to account for the size of the population that didn't have COVID-19 when using a machine learning model?

### Roles

* **Project Manager**
    * David
* **Database Storage**
    * Dinah
    * Kimi
    * Michael
* **Data Cleaning and Analysis**
    * Dinah
    * Kimi
    * Michael
* **Machine Learning Model**
    * Michael
* **Presentation of Findings**
    * Yodit (Tableau)
    * Jack (Tableau)
    * David (approver) & Team (GitHub)

### Technologies Used

* **Database Storage**
    * pgAdmin - PostgreSQL
    * AWS RDS
* **Data Cleaning and Analysis**
    * Juypter Notebook - Pandas
* **Machine Learning Model**
    * Google Collab Notebook
* **Presentation of Findings**
    * Tableau Public
    * GitHub

### Communication Protocol 

* [Project Checklist](https://docs.google.com/spreadsheets/d/1G9lvPyMrlkjnYT-qGigKpNdVk72A9Zu0Je7hyy8Q6ug/edit?usp=sharing)
* [Group meeting agendas](https://drive.google.com/drive/folders/1sMOLvKQO-S99917fQL9axuocZujgKNZQ?usp=sharing)

We are meeting twice a week outside of class on Zoom and consistently communicating over Slack. David has established best pratices in GitHub, so we don't overwrite each other's work.

## Data Exploration and Analysis Phases

### Data Exploration and Analysis Overview

We began the project by looking at the entirety of COVID-19 CDC data, which consists of 27 million rows and 19 columns of unique patient information. We quickly realized that if we wanted to replicate the spread of COVID-19 based on any factor, we needed to account for the population that didn't have the disease. We established **Number of COVID-19 Cases / State Population** as our target variable. We found ratio would be easier to handle data-wise than working with large population datasets or creating pseudo population data. Next, we moved on to categorical factors. 

For social factors, we looked at U.S. Census data estimates for information on sex, age, and race. We observed that both datasets had either state abbreviations or states spelled out with their full names. We knew we could join data tables by state, so we focused our efforts on finding geographical, economic, lifestyle and political factors with state columns already available.

### Datasets and Sources

* [Joined and cleaned COVID-19 dataset with factors](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv) 
* [COVID-19 Cases by Age, Sex, Race](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv) Source: U.S. Census and CDC
* [U.S. Commercial Airports by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/Group4%20Airport%20By%20Area.csv) Source: FAA
* [State Mask Mandate Policy/Political Affiliation by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/state_factors_from_gallup.csv) Source: Gallup
* [Median Household Income by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/household_income_by_state.csv) Source: U.S. Census

### Description of Data Sources

As stated in the Data Exploration subheading, our original dataset consisted of over 27 million rows of unique patient Covid-19 data sourced from the Center for Disease Control and Prevention (CDC) Case Surveillance Public Use Data. Having analyzed the quality of our data, the Team pivoted to finding additional, specific data that would support our model, have minimum missing data and null values and to answer our investigative questions with a unique perspective. Our primary and final dataset will be constructed by merging primary demographic information from the Center of Disease Control & Prevention (CDC), US census data from US Census Bureau and qualitative survey data from Gallup that will consist of 50 rows of State values and 50-55 columns of factors.  

## Database

### Database Schema ERD

Joining factor data by state (see step 7 below):
![COVID_MARCH2020_DEC2020_PROJECT4%20ERD](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Images/COVID_MARCH2020_DEC2020_PROJECT4%20ERD.png)

Joining cleaned CDC data by state (see step 8 below):
![COVID_MARCH2020_DEC2020_PROJECT4_CDC%20ERD](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Images/COVID_MARCH2020_DEC2020_PROJECT4_CDC%20ERD.png)

### Building the Database

[Database Storing Overview](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/Project%204%20Database%20SQL_steps.txt)

**Steps**

1. We chose input data from CDC from March - December 2020 because March marked when the U.S. declared a state of emergency and December was when the first COVID-19 vaccine dose was administered and U.S. Census data, so we replicate the spread of COVID-19 and account for people who didn't have the disease (as mentioned in the Data Exploration section)
2. Because it was such a large dataset, we split it into 4 parts so cleaning it was more manageable. These parts were imported to the table: CDC_INPUTDB_CLEANED
3. We also used our data from investigating factors into their respective tables: 
   - household_income_by_state into ST_INCOME
   - state_factors_from_gallup into US_POLITICS
   - census_sex_no_covid into CENSUS_SEX
   - census_age_no_covid into CENSUS_RACE
4. After storing the data in pgAdmin - PostgreSQL, we created new tables from CDC_INPUTDB_CLEANED and then segmented age group, state, sex, and race. Here's a review of all the tables we worked with and new columns we created for the final table, for visual, please refer to the ERD above:
   - Table: DATA_AGE_GROUP, COVID_CASES_AGE, New columns: COVID and NO COVID for each group: age_group_0_17, age_group_18_49, age_group_50_64, age_group_65PLUS
   - Table: US_STATES, New columns: none
   - Table: DATA_SEX, COVID_CASES_SEX, NOCOVID_CENSUS_SEX, New columns: COVID and NO COVID for each group: Male, Female
   - Table: DATA_RACE, COVID_CASES_RACE, New columns: COVID and NO COVID for each group: Asian, Black, Multiple/Other, White, American Indian/Alaska Native, Native Hawaiian/Other Pacific Islander, No_identified_race
   - Table: US_POLITICS, New columns: Nearly 30 new political and lifestyle columns with data on information on mask mandates, political party, exercise frequency, sense of community, etc. 
   - Table: AIRPORT_BY_AREA, New columns: total airports, state land area (sq. miles), airport area (airports per sq. mile)
   - Table: ST_INCOME, New columns: median income
5. We identified that we could join all tables using the states column. Using the table: US_STATES, we created the table: COVID_MARCH2020_DEC2020_PROJECT4, of totals per state, with calculated data from the table: CDC_INPUTDB_CLEANED
6. Using the table: US_STATES, we added all the tables with totals, and created the table: COVID_MARCH2020_DEC2020_TOTALS_PROJECT4
7. Next, we joined all tables by **state** to input data from all tables to COVID_MARCH2020_DEC2020_TOTALS_PROJECT4. 
   - Please refer to the **first ERD image** for the visual of this process
8. Simiarly, with the cleaned CDC_INPUTDB_CLEANED table mentioned in **step 2 and step 3**, we joined the tables by state and input the data to COVID_MARCH2020_DEC2020_TOTALS_PROJECT4 as well. 
   - Please refer to the **second ERD image** for the visual of this process
9. We exported our table COVID_MARCH2020_DEC2020_TOTALS_PROJECT4 from pgAdmin to the csv file: [COVID_MARCH2020_DEC2020_TOTALS_PROJECT4](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv)

### Data Dictionary

![image](https://user-images.githubusercontent.com/79073778/126433251-84f72a83-93df-47fc-9797-425836639f47.png)

## ETL Method

### Extracting the Data
Our main dataset was COVID-19 CDC data, which consists of unique patient information spanning 19 columns and 27 million rows. With such a large dataset, we used Amazon S3 to store the data and used Google Colab with Pyspark to access and load the data.

### Transforming the Data
With the data loaded, we could now transform our data. We first filtered the data to be between March 2020 and December 2020. We chose this date range because March 2020 was when the United States declared COVID-19 a pandemic and December 2020 was when the first vaccine was administered in the United States. After filtering the data by date, we dropped many columns from the dataset for either or both of these reasons: 1) there were too many missing values for the variable to be usable and/or 2) the variable was not useful for our analysis. After dropping the unnecessary columns, the data was left with four variables: res_state, age_group, sex, and race. The dataset also had missing values which were identified in the data as either "Missing", "Unknown", or "NA". We replaced all the "Missing" and "Unknown" values to be "NA" for simplicity in identifying the missing values. The data was then exported to a CSV file where it was then imported into SQL for storage and further querying.

### Loading the Data
We used SQL to store the data and query it so that the data would be organized by state with the values becoming our new features. For example, we now have "Male" and "Female" as features of our data with totals of each for each state, whereas in the base CDC data, "sex" was the feature and "Male" and "Female" were values for the unique patients. The other features we are using were imported from their respective CSV files and joined to this main table. Using the U.S. Census data, we were able to create the features for those who do not have COVID by subtracting the number of people with COVID by the total numbers for each state. For example, to find the total number of females who do not have COVID for the state of Maryland, we subtracted the total number of females with COVID from the total population of the state of Maryland.

### Handling Missing Values
The CDC dataset we used had many missing values for the patients age, sex, and race. This is to be expected as many people opt out of providing such information. Because machine learning models cannot run with null values, we had to find a way to handle the missing values. We came up with four possible strategies:

1. Delete the observations with missing values.
2. Delete the variable.
3. As the features with missing values are categorical variables, we could impute the missing values by using the mode.
4. We can predict the missing values for the categorical variables by using a classification model. We would split the data as such:
  - y_train: rows from data with non null values
  - y_test: rows from data with null values
  - X_train: Dataset except data features with non null values
  - X_test: Dataset except data features with null values

We did not want to delete observations as that would mean less data and also would misrepresent the total number of COVID cases. We also did not want to delete the variables as we felt age, sex, and race are important variables for understanding the spread of COVID. For age and sex, we decided to impute the missing values with the mode, as both variables had very low numbers of missing values (1% and 3% respectively). Race, however, had about 42% of missing data. Imputing the data with the mode would not be effective here as a few states had no race data at all. However, we felt that even though there were many missing values for race, the lack of data has something to show for itself. There is strong analysis that can be made on why that data is missing and exposes the weaknesses in data collection on behalf of the CDC and state governments, demonstrating how disjointed states were in their response to COVID and data collection, and on such a crucial factor such as race. That being said, the missing values still had to be accounted for in order for the data to be run through a machine learning model. Therefore, the total number of missing values for each state were put into its own column.

We also were originally going to look at data for all 50 US states and DC. Unfortunately, the Gallup data that we are using for most of our features recorded no data for DC and we therefore had to remove DC from our dataset.

## Machine Learning

### Model Choice
The model we chose to use is a **supervised random forest regression model.** We chose supervised machine learning because we have labeled data (our features in tabular form) and outputs. The input data, or our features, has a paired outcome which is plugged in to train the model to predict outcomes. Supervised machine learning models have target variables, or dependent variables, about which we want to gain a deeper understanding. In our case our target variable is how much effect COVID had on a state's population by looking at the total number of COVID cases divided by the total state population.

We chose a random forest algorithm because it can handle many input variables of which we have many. The algorithm can run efficiently on large datasets, and most importantly, random forest models can be used to rank the importance of input variables. This fits the question we are trying to answer perfectly - **what are the top factors that influence the spread of COVID?** A random forest model will help us rank the most influential factors. Since we have a large dataset with many features, as well as both continuous and categorical non-linear variables, a random forest algorithm will be more efficient and more accurate than a simple linear regression. While a large number of trees in a random forest algorithm can be slow requiring a lot of computational power and resources, the advantages outweigh the disadvantages.

### Code for Random Forest Model
To create the random forest model, we first initialize the dependencies, notably the 'from sklearn.ensemble import RandomForestRegressor'.

```
import pandas as pd
import numpy as np
from path import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import metrics
```

After loading in the data, we use one hot encoding to account for null values and convert categorical variables to integer data.

```
file_path = ("COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv")
covid_df = pd.read_csv(file_path)

covid_cat = covid_df.dtypes[covid_df.dtypes == "object"].index.tolist()

from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder(sparse=False)
encode_df = pd.DataFrame(enc.fit_transform(covid_df[covid_cat]))

encode_df.columns = enc.get_feature_names(covid_cat)
encode_df.head()
```

We then merge the one hot encoded features to the main dataframe and drop the originals.

```
covid_df = covid_df.merge(encode_df, left_index=True, right_index=True)
covid_df = covid_df.drop(covid_cat,1)
covid_df
```

We split our preprocessed data into our features and target variables.

```
y = covid_df["case_pop"].ravel()
X = covid_df.copy()
X = X.drop("case_pop", axis=1)
```

We then split the data into training and testing sets and scale the data. We set random_state to a number in the testing phase so that we can consistently see the same results when the test model is run (this could possibly be removed for the final model).

```
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

scaler = StandardScaler()

X_scaler = scaler.fit(X_train)

X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)
```

We initialize the random forest classifier and fit the model. We set n_estimators to 128 because best practice is to use between 64 and 128 forests. Generally, the higher the number, the stronger and more stable the predictions are. Given that this is a test model, it is reasonable to assume the model might be able to handle 128 forests.

```
rf_model = RandomForestRegressor(n_estimators=128, random_state=1) 

rf_model = rf_model.fit(X_train_scaled, y_train)
```

We make predictions and then evaluate performance using the Mean Absolute Error, Mean Squared Error, and the Root Mean Squared Error.

```
y_pred = rf_model.predict(X_test_scaled)

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
```

We finally rank the importance of the features and see which have the most impact on the output.

```
importances = rf_model.feature_importances_
importances

sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)
```

## Dashboard

### [Tableau Dashboard Demo](https://public.tableau.com/views/THECOVIDPLAYBOOKDASHBOARD/THECOVIDPLAYBOOKDASHBOARD_1?:language=en-US&:display_count=n&:origin=viz_share_link)

### Blueprint and Interactive Elements

One of the interactive elements we are using is the filter action. Filter actions send information between worksheets. Typically, a filter action sends information from a selected mark to another sheet showing related information. Behind the scenes, filter actions send data values from the relevant source fields as filters to the target sheet and dashboards.

For example, in a view showing the states, when a user selects a particular state name, a filter action can show all state values for all the displayed variables. 
User can select marks to see information about a specific data filed. One can also select an individual mark or multiple ones by holding down the Ctrl key (for Windows) or the Command key (macOS).

When you select marks in the view, all other marks are dimmed to draw attention to the selection. The selection is saved with the workbook. Quick data view can also be done by one of the run-on options; hovering your mouse on the charts/marks. 

We have also created a simple HTML file to show the dashboard in a dedicated webpage with another interactive element where users can download the analysis into PDF file. 





## Deliverable 4



During this final week, complete the last of the preparations before presenting. You've worked hard, so show off a bit! Highlight some tricky code you may have used! Show off a unique visualization. Talk through your approach and definitely flex your knowledge.

Let's look at this segment's role:

Team: Practice presenting your portion of the presentation. Tie up any loose ends related to the project (analysis, machine learning, dashboard, etc.).
Square: Final updates to the README.md on the project repository (make sure there is a description of the project, explain why this topic was chosen, include images from the analysis, and the conclusion)—make the repository portfolio-ready.
Circle: Ensure all applicable PRs are merged in (includes finishing up peer reviews and merging branches). Conduct final editorial review (clean up code to meet coding guidelines, check for typos, clarity, etc.).
Triangle: Final touches on visual aspects with the presentation and dashboard. Make sure the images tell the story cleanly and clearly.
X: Review the rubric and ensure the project meets the requirements, and test the code.

Presentation (25 points)
Content
The presentation tells a cohesive story about the project and includes the following:

Selected topic
Reason the topic is selected
Description of the source of data
Questions the team hopes to answer with the data
Description of the data exploration phase of the project
Description of the analysis phase of the project
Technologies, languages, tools, and algorithms used throughout the project
Result of the analysis
Recommendation for future analysis
Anything the team would have done differently
Slides
Presentations are finalized in Google Slides and should include:

Slides are primarily images or graphics (rather than primarily text).
Images are clear, in high-definition, and directly illustrative of subject matter.
Live Presentation
The team members deliver the presentation in equal proportions. The live presentation should include the following:

Demonstrates the interactivity of the dashboard in real time
Adheres to the time limits provided by instructor
Includes speaker notes, flashcards, or a video of the presentation rehearsal
GitHub Repository (10 points)
Main Branch
All code in the main branch is production-ready. All code is clean, commented, easy to read, and adheres to a coding standard (e.g., PEP8).

The main branch should include:

All code necessary to perform exploratory analysis
All code necessary to complete machine learning portion of project
Any images that have been created (at least three)
Requirements.txt file
README.md
The README.md should include:

Cohesive, structured outline of the project (this may include images, but they should be easy to follow and digest)
Link to dashboard (or link to video of dashboard demonstration)
Link to Google Slides presentation
IMPORTANT
The descriptions and explanations required in all other project deliverables should also be in your READme.md as part of your outline, unless otherwise noted.

Individual Branches
Requirements for the individual branches follow:

At least one branch for each team member
Each team member has at least four commits for the duration of the final segment (16 total commits per person)
Link to Google Slides draft presentation
Machine Learning Model (25 points)
Students will be expected to submit the working code for their machine learning model, as well as the following:

Description of data preprocessing
Description of feature engineering and the feature selection, including the decision-making process
Description of how data was split into training and testing sets
Explanation of model choice, including limitations and benefits
Explanation of changes in model choice (if changes occurred between the Segment 2 and Segment 3 deliverables)
Description of how the model was trained (or retrained, if the team is using an existing model)
Description and explanation of model's confusion matrix, including final accuracy score
Additionally, the model obviously addresses the question or problem the team is solving.

IMPORTANT
If statistical analysis is not included as part of the current analysis, the team should describe how it would be included in the next phases of the project.

Database Integration (25 points)
Students will be expected to present a final project with a fully integrated database.

Database stores static data for use during the project

Database interfaces with the project in some format (e.g., scraping updates the database)

Includes at least two tables (or collections, if using MongoDB)

Includes at least one join using the database language (not including any joins in Pandas)

Includes at least one connection string (using SQLAlchemy or PyMongo)

IMPORTANT
If you use a SQL database, you must provide your ERD with relationships.

Dashboard (15 points)
The dashboard presents a data story that is logical and easy to follow for someone unfamiliar with the topic. It includes all of the following:

Images from the initial analysis
Data (images or report) from the machine learning task
At least one interactive element
Either the dashboard is published or the submission includes a screen capture video of it in action.



## Deliverable 4 (final)

# Coronavirus Pandemic Playbook
_A Project by: David Watson, Dinah Bondzie, Michael Leggett, Kimi Ellerbe, Jack Gross, Yodit Teamir_

## Project Topic, Background, Audience

The term 'pandemic playbook' circulated in the news during the beginning of the COVID-19 pandemic. U.S. President Barack Obama's team had outlined how to respond to infectious diseases and biological incidents so future administrations would be prepared to respond to the next pandemic or biological threat. While the federal government prepared guidelines, state governments from the 50 states + DC were woefully unprepared for a pandemic. The COVID-19 pandemic brought the [deepest recession since the end of WWII](https://www.brookings.edu/research/social-and-economic-impact-of-covid-19/) as the global economy shrunk by 3.5% and [114 million](https://www.weforum.org/agenda/2021/02/covid-employment-global-job-loss/) people lost their jobs in 2020. The impact of this shock is likely to be felt for years to come.

The National Governors Association, a nonpartisan organization comprised of governors in the U.S., tasked with creating an updated playbook for state governments. They have asked us to provide a comprehensive review of factors that led to the spread of COVID-19 cases in states across the United States. We will be presenting ours at the next National Governors Association annual conference in late 2021.

<img src="Images/pandemic_playbook.jpg" width="600">

### Project Goal
Drawing on data from CDC, U.S. Census, and many other sources, our goal is to determine which social, economic, and political factors contributed to the spread of COVID-19. There is evidence that if states were more prepared to handle a pandemic, economic performance would not have suffered as it did in 2020. Our nation's governors have the opportunity to learn where our state's weak points were that led to these incredible economic losses and mitigate them in a future pandemic. Our team is confident that our machine learning algorithm will predict which factors contributed the most to the spread of respiratory diseases like COVID-19. The information will be valuable for state lawmakers' future economic and social political decisions.

### Project Factors 

Given our audience for the project, the data we've obtained for each factor will be organized by state. 

**Target Variable**
* Number of COVID-19 Cases / State Population

**Social Factors**
* Sex
* Age
* Race
* Religion

**Geographical Factors**
* Population Density
* Number of Commercial Airports / State Land Area

**Economic Factors**
* Median Household Income

**Political Factors**
* State Mandates / COVID-19 rules
* Political Leaning

**Lifestyle Factors**
* Health Insurance Coverage 
* Exercise Frequency
* Social Inclusivity 
* Work Life Status
* Monetary Stability

### Questions to Investigate During Project
1. Which social, economic, geographical, lifestyle or political factors contributed the most the spread of the disease?
2. Which category of factor contributed the most to the spread of the disease?
3. Is there a connection between state policy or political leaning (i.e. mask mandate) and the spread of COVID-19 within the state
4. Do we need to account for the size of the population that didn't have COVID-19 when using a machine learning model?

### Roles

* **Project Manager**
    * David
* **Database Storage**
    * Dinah
    * Kimi
    * Michael
* **Data Cleaning and Analysis**
    * Dinah
    * Kimi
    * Michael
* **Machine Learning Model**
    * Michael
* **Presentation of Findings**
    * Yodit (Tableau)
    * Jack (Tableau)
    * David (approver) & Team (GitHub)

### Technologies Used

* **Database Storage**
    * pgAdmin - PostgreSQL
    * AWS RDS
* **Data Cleaning and Analysis**
    * Juypter Notebook - Pandas
* **Machine Learning Model**
    * Google Collab Notebook
* **Presentation of Findings**
    * Tableau Public
    * GitHub

### Communication Protocol 

* [Project Checklist](https://docs.google.com/spreadsheets/d/1G9lvPyMrlkjnYT-qGigKpNdVk72A9Zu0Je7hyy8Q6ug/edit?usp=sharing)
* [Group meeting agendas](https://drive.google.com/drive/folders/1sMOLvKQO-S99917fQL9axuocZujgKNZQ?usp=sharing)

We are meeting twice a week outside of class on Zoom and consistently communicating over Slack. David has established best pratices in GitHub, so we don't overwrite each other's work.

## Data Exploration and Analysis Phases

### Data Exploration and Analysis Overview

We began the project by looking at the entirety of COVID-19 CDC data, which consists of 27 million rows and 19 columns of unique patient information. We quickly realized that if we wanted to replicate the spread of COVID-19 based on any factor, we needed to account for the population that didn't have the disease. We established **Number of COVID-19 Cases / State Population** as our target variable. We found ratio would be easier to handle data-wise than working with large population datasets or creating pseudo population data. Next, we moved on to categorical factors. 

For social factors, we looked at U.S. Census data estimates for information on sex, age, and race. We observed that both datasets had either state abbreviations or states spelled out with their full names. We knew we could join data tables by state, so we focused our efforts on finding geographical, economic, lifestyle and political factors with state columns already available.

### Datasets and Sources

* [Joined and cleaned COVID-19 dataset with factors](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv) 
* [COVID-19 Cases by Age, Sex, Race](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv) Source: U.S. Census and CDC
* [U.S. Commercial Airports by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/Group4%20Airport%20By%20Area.csv) Source: FAA
* [State Mask Mandate Policy/Political Affiliation by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/state_factors_from_gallup.csv) Source: Gallup
* [Median Household Income by State](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/household_income_by_state.csv) Source: U.S. Census

### Description of Data Sources

As stated in the Data Exploration subheading, our original dataset consisted of over 27 million rows of unique patient Covid-19 data sourced from the Center for Disease Control and Prevention (CDC) Case Surveillance Public Use Data. Having analyzed the quality of our data, the Team pivoted to finding additional, specific data that would support our model, have minimum missing data and null values and to answer our investigative questions with a unique perspective. Our primary and final dataset will be constructed by merging primary demographic information from the Center of Disease Control & Prevention (CDC), US census data from US Census Bureau and qualitative survey data from Gallup that will consist of 50 rows of State values and 50-55 columns of factors.  

## Database

### Database Schema ERD

Joining factor data by state (see step 7 below):
![COVID_MARCH2020_DEC2020_PROJECT4%20ERD](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Images/COVID_MARCH2020_DEC2020_PROJECT4%20ERD.png)

Joining cleaned CDC data by state (see step 8 below):
![COVID_MARCH2020_DEC2020_PROJECT4_CDC%20ERD](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Images/COVID_MARCH2020_DEC2020_PROJECT4_CDC%20ERD.png)

### Building the Database

[Database Storing Overview](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/Project%204%20Database%20SQL_steps.txt)

**Steps**

1. We chose input data from CDC from March - December 2020 because March marked when the U.S. declared a state of emergency and December was when the first COVID-19 vaccine dose was administered and U.S. Census data, so we replicate the spread of COVID-19 and account for people who didn't have the disease (as mentioned in the Data Exploration section)
2. Because it was such a large dataset, we split it into 4 parts so cleaning it was more manageable. These parts were imported to the table: _CDC_INPUTDB_CLEANED_
3. We also used our data from investigating factors into their respective tables: 
   - household_income_by_state into _ST_INCOME_
   - state_factors_from_gallup into _US_POLITICS_
   - census_sex_no_covid into _CENSUS_SEX_
   - census_age_no_covid into _CENSUS_RACE_
4. After storing the data in pgAdmin - PostgreSQL, we created new tables from _CDC_INPUTDB_CLEANED_ and then segmented age group, state, sex, and race. Here's a review of all the tables we worked with and new columns we created for the final table, for visual, please refer to the ERD above:
   - Table: _DATA_AGE_GROUP, COVID_CASES_AGE_, New columns: _COVID_ and _NO COVID_ for each group: _age_group_0_17, age_group_18_49, age_group_50_64, age_group_65PLUS_
   - Table: _US_STATES_, New columns: none
   - Table: _DATA_SEX, COVID_CASES_SEX, NOCOVID_CENSUS_SEX,_ New columns: _COVID_ and _NO COVID_ for each group: _Male, Female_
   - Table: DATA_RACE, COVID_CASES_RACE, New columns: COVID and _NO COVID_ for each group: _Asian, Black, Multiple/Other, White, American Indian/Alaska Native, Native Hawaiian/Other Pacific Islander, No_identified_race_
   - Table: _US_POLITICS_, New columns: Nearly 30 new political and lifestyle columns with data on information on mask mandates, political party, exercise frequency, sense of community, etc. 
   - Table: _AIRPORT_BY_AREA_, New columns: total airports, state land area (sq. miles), airport area (airports per sq. mile)
   - Table: _ST_INCOME_, New columns: median income
5. We identified that we could join all tables using the states column. Using the table: _US_STATES_, we created the table: _COVID_MARCH2020_DEC2020_PROJECT4_, of totals per state, with calculated data from the table: _CDC_INPUTDB_CLEANED_
6. Using the table: _US_STATES_, we added all the tables with totals, and created the table: _COVID_MARCH2020_DEC2020_TOTALS_PROJECT4_
7. Next, we joined all tables by **state** to input data from all tables to _COVID_MARCH2020_DEC2020_TOTALS_PROJECT4_. 
   - Please refer to the **first ERD image** for the visual of this process
8. Simiarly, with the cleaned CDC_INPUTDB_CLEANED table mentioned in **step 2 and step 3**, we joined the tables by state and input the data to _COVID_MARCH2020_DEC2020_TOTALS_PROJECT4_ as well. 
   - Please refer to the **second ERD image** for the visual of this process
9. We exported our table _COVID_MARCH2020_DEC2020_TOTALS_PROJECT4_ from pgAdmin to the csv file: [COVID_MARCH2020_DEC2020_TOTALS_PROJECT4](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/COVID_MARCH2020_DEC2020_TOTALS_PROJECT4.csv)

### Data Dictionary

![image](https://user-images.githubusercontent.com/79073778/126433251-84f72a83-93df-47fc-9797-425836639f47.png)

## ETL Method

### Extracting the Data
Our main dataset was COVID-19 CDC data, which consists of unique patient information spanning 19 columns and 27 million rows. With such a large dataset, we used Amazon S3 to store the data and used Google Colab with Pyspark to access and load the data.

### Transforming the Data
With the data loaded, we could now transform our data. We first filtered the data to be between March 2020 and December 2020. We chose this date range because March 2020 was when the United States declared COVID-19 a pandemic and December 2020 was when the first vaccine was administered in the United States. After filtering the data by date, we dropped many columns from the dataset for either or both of these reasons: 1) there were too many missing values for the variable to be usable and/or 2) the variable was not useful for our analysis. After dropping the unnecessary columns, the data was left with four variables: res_state, age_group, sex, and race. The dataset also had missing values which were identified in the data as either "Missing", "Unknown", or "NA". We replaced all the "Missing" and "Unknown" values to be "NA" for simplicity in identifying the missing values. The data was then exported to a CSV file where it was then imported into SQL for storage and further querying.

### Loading the Data
We used SQL to store the data and query it so that the data would be organized by state with the values becoming our new features. For example, we now have "Male" and "Female" as features of our data with totals of each for each state, whereas in the base CDC data, "sex" was the feature and "Male" and "Female" were values for the unique patients. The other features we are using were imported from their respective CSV files and joined to this main table. Using the U.S. Census data, we were able to create the features for those who do not have COVID by subtracting the number of people with COVID by the total numbers for each state. For example, to find the total number of females who do not have COVID for the state of Maryland, we subtracted the total number of females with COVID from the total population of the state of Maryland.

### Handling Missing Values
The CDC dataset we used had many missing values for the patients age, sex, and race. This is to be expected as many people opt out of providing such information. Because machine learning models cannot run with null values, we had to find a way to handle the missing values. We came up with four possible strategies:

1. Delete the observations with missing values.
2. Delete the variable.
3. As the features with missing values are categorical variables, we could impute the missing values by using the mode.
4. We can predict the missing values for the categorical variables by using a classification model. We would split the data as such:
  - y_train: rows from data with non null values
  - y_test: rows from data with null values
  - X_train: Dataset except data features with non null values
  - X_test: Dataset except data features with null values

We did not want to delete observations as that would mean less data and also would misrepresent the total number of COVID cases. We also did not want to delete the variables as we felt age, sex, and race are important variables for understanding the spread of COVID. For age and sex, we decided to impute the missing values with the mode, as both variables had very low numbers of missing values (1% and 3% respectively). Race, however, had about 42% of missing data. Imputing the data with the mode would not be effective here as a few states had no race data at all. However, we felt that even though there were many missing values for race, the lack of data has something to show for itself. There is strong analysis that can be made on why that data is missing and exposes the weaknesses in data collection on behalf of the CDC and state governments, demonstrating how disjointed states were in their response to COVID and data collection, and on such a crucial factor such as race. That being said, the missing values still had to be accounted for in order for the data to be run through a machine learning model. Therefore, the total number of missing values for each state were put into its own column.

We also were originally going to look at data for all 50 US states and DC. Unfortunately, the Gallup data that we are using for most of our features recorded no data for DC and we therefore had to remove DC from our dataset. We had to drop Delaware, Louisiana, Mississippi, North Dakota, and Wyoming because they either had no data for race or their numbers for race were extremely inaccurate. We also had to drop Michigan, Missouri, Kentucky, Rhode Island, South Dakota, Texas, and West Virginia as their COVID numbers were also exteremely inaccurate and way under what they should have been in the period between March 2020 and December 2020.

## Machine Learning

### Model Choice
The model we chose to use is a **supervised random forest regression model.** We chose supervised machine learning because we have labeled data (our features in tabular form) and outputs. The input data, or our features, has a paired outcome which is plugged in to train the model to predict outcomes. Supervised machine learning models have target variables, or dependent variables, about which we want to gain a deeper understanding. In our case our target variable is how much effect COVID had on a state's population by looking at the total number of COVID cases divided by the total state population.

We chose a random forest algorithm because it can handle many input variables of which we have many. The algorithm can run efficiently on large datasets, and most importantly, random forest models can be used to rank the importance of input variables. This fits the question we are trying to answer perfectly - **what are the top factors that influence the spread of COVID?** A random forest model will help us rank the most influential factors. Since we have a large dataset with many features, as well as both continuous and categorical non-linear variables, a random forest algorithm will be more efficient and more accurate than a simple linear regression. While a large number of trees in a random forest algorithm can be slow requiring a lot of computational power and resources, the advantages outweigh the disadvantages.

### Code for Random Forest Model

[Link to COVID-19 Machine Learning Notebook](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/covid_ml.ipynb)

We originally ran the data with absolute values through the model. Based on the accuracy scores, the model suffered from extreme overfitting. Also, the model might not be very accurate because the data used had absolute values instead of ratios, which would be more appropriate and representative of the data. Here were the accuracy scores and results of that model:

Accuracy

![Accuracy](Resources/accuracy.PNG)

Feature Importance

![Results](Resources/features_ranked.PNG)

We ran the model again, this time using ratios instead of absolute values in the data.

To create the random forest model, we first initialize the dependencies, notably the 'from sklearn.ensemble import RandomForestRegressor'.

```
import pandas as pd
import numpy as np
from path import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import metrics
```

After loading in the data, we use one hot encoding to convert categorical variables to integer data.

```
file_path = ("COVID_MARCH2020_DEC2020_RATIOS_PROJECT4.csv")
covid_df = pd.read_csv(file_path)

covid_cat = covid_df.dtypes[covid_df.dtypes == "object"].index.tolist()

from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder(sparse=False)
encode_df = pd.DataFrame(enc.fit_transform(covid_df[covid_cat]))

encode_df.columns = enc.get_feature_names(covid_cat)
encode_df.head()
```

We then merge the one hot encoded features to the main dataframe and drop the originals.

```
covid_df = covid_df.merge(encode_df, left_index=True, right_index=True)
covid_df = covid_df.drop(covid_cat,1)
covid_df
```

We split our preprocessed data into our features and target variables.

```
y = covid_df_encode["target_var_covid_st"].ravel()
X = covid_df_encode.copy()
X = X.drop("target_var_covid_st", axis=1)
```

We then split the data into training and testing sets and scale the data. We set random_state to a number in the testing phase so that we can consistently see the same results when the test model is run (this could possibly be removed for the final model).

```
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

scaler = StandardScaler()

X_scaler = scaler.fit(X_train)

X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)
```

We initialize the random forest regressor and fit the model. We set n_estimators to 500 since generally the higher the number, the stronger and more stable the predictions are. Given that there are not too many observations, it is reasonable to assume the model might be able to handle 500 forests.

```
rf_model = RandomForestRegressor(n_estimators=500, random_state=1) 

rf_model = rf_model.fit(X_train_scaled, y_train)
```

We make predictions and then evaluate performance using the Mean Absolute Error, Mean Squared Error, and the Root Mean Squared Error.

```
y_pred = rf_model.predict(X_test_scaled)

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
```

![Ratio Accuracy](Resources/accuracy_ratio2.PNG)

The mean absolute error and root mean squared error are sizeable but the mean squared error is very high, meaning we are very far from finding the line of best fit.

We finally rank the importance of the features and see which have the most impact on the output.

```
importances = rf_model.feature_importances_
importances

sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)
```

![Ratio Results](Resources/results_ratio2.PNG)

Not too surprisingly, we find that population density is the highest ranked factor at 75%. As more people are densely close together, the more likely COVID is to spread from person to person.

To see how the model would rank the features without population density as a factor, we removed the population_density and state_land_area_sqmile columns as they are both similar in relation and the state_land_area_sqmile column is not a necessary feature in running the model.

![Ratio Accuracy](Resources/accuracy_ratio.PNG)

We see drastically different accuracy scores from the previous run of the model. The mean absolute error and the root mean squared error are quite good, but the mean squared error is arguably high but significantly better than it was before.. Because of how we aggregated our data by state and because we only have 36 observations, it might be impossible to get the mean squared error any smaller. However, we did see some very interesting results:

![Ratio Results](Resources/results_ratio.PNG)

The state policy prevention mandate score is the top most important factor in the spread of COVID with Trump disapproval trailing close behind. The 50-64 age group airport per square mile, economic confidence index, and 0-17 age group are also fairly large factors that contributed to the spread of COVID.

We realized that there were some potential problems with our model - since we only have 36 observations and all of them individual states, the machine learning model is taking 75% of those states and predicting for the other 25% which is problematic as each state is so different demographically, in its response to COVID, etc. We were also unable to run individual models for each state because of the aggregation. So, we also tried a different approach - keeping in line of our overall question about the top factors leading to the spread of COVID, what if we could use the individual patient data and use whether or not a person has covid as the target variable? It is a good idea in theory, however, the only data we have is for individual patients with COVID. We know from simple subtraction of the (total population - total number of covid cases) how many total people don't have COVID, but we know nothing about the individual people. From the CDC data, we were able to see each person with COVID's age range, sex, and race. In order to get that data for the people without COVID, we used feature engineering to create those values based on Census statistics.

For example, for Connecticut, we looked at the Census data and calculated what percentage of the non-COVID people would be in each age bracket, male or female, and what their race would be and used those percentages as probabilities to create the non-COVID data.

```
# Connecticut
def faker_categorical(num=1, seed=None):
  np.random.seed(seed)
  fake.seed_instance(seed)

  output = [
    {
        "res_state": "CT",
        # age_group: 0: 0-17 years, 1: 18-49 years, 2: 50-64 years, 3: 65+ years
        "age_group": np.random.choice(["0", "1", "2", "3"], p=[0.21, 0.40, 0.21, 0.18]),
        # sex: 0-Male, 1-Female
        "sex": np.random.choice(["0", "1"], p=[0.49, 0.51]),
        # race: 0-White, 1-Black, 2-Asian, 3-American Indian/Alaska Native, 4-Native Hawaiian/Other Pacific Islander, 5-Multiple/Other
        "race": np.random.choice(["0", "1", "2", "3", "4", "5"], p=(0.7461, 0.1113, 0.0467, 0.0025, 0.0004, 0.0930)),
    }
    for x in range(num)
  ]
  return output
  ```
  
Using these probabilites, we had the script create a certain number of rows equal to the total non-COVID population for each state. In the case of Connecticut, there were 3,394,611 people without COVID and the script created that many rows using the probabilites we gave it above.
  
  ```
  ct_df = pd.DataFrame(faker_categorical(num=3394611, seed=0))
  ```

Doing this for every state creates a lot of data. Doing this for all 38 states we were using created almost 250 million rows. While we would have liked to run a machine learning model on this data, we did not have the necessary infrastructure to run this data as we lacked the necessary RAM or memory. We tried using Google Colab Pro and their 25GB of RAM but it still was not enough. Therefore, we decided to pick one state from each region in the United States - Northeast, Southeast, Midwest, West, Southeast, and Southwest - for a total of five states. The states we chose were Connecticut, Tennessee, Wisconsin, Utah, and Oklahoma as these were also relatively the same size population wise.

We also added additional factors to the data including the states' region, population density, median income, airport per square mile, and COVID policy pervention score. In order to help make the data less memory intensive, the categorical data was also ordinally encoded. The final table looked as such:

![Table](Resources/table.PNG)

After the data preprocessing was complete, we ran the data through a random forest classification model.

![Confusion Matrix](Resources/confusion_matrix.PNG)

0 is a Yes for COVID and 1 is a No for COVID. As we can see from the confusion matrix, the model was excellent at prediciting non-COVID cases and not great a predicting COVID cases. Non-COVID cases make up a vast majority of the data and therefore has a lot more data to learn from and make accurate predictions. While its prediction power isn't the best, it produced interesting results for ranking the factors:

![Results](Resources/new_model_results.PNG)

Race was essentially the single most important feature at 94%, followed by age and population density at 2% and 1% respectively. This is misleading, however. We think the model is relying on the "Not Identified" variable for race in the COVID data. The feature engineered data does not have a "Not Identified" variable. We also know that the "Not Identified" variable makes up about 40% of the overall data, meaning that for these five states we chose, there are a significant number of "Not Identified" which are linked only to COVID cases. To test this theory, we ran the model without the race column.

![Confusion Matrix](Resources/confusion_matrix2.PNG)

As we can see, the model was not able to predict COVID cases at all without the race data. The broader issue is that the data is extremely unbalanced - there are significantly more non-COVID cases than COVID cases. This could be solved by using SMOTE or SMOTEENN, however, we do not have the time or resources to run that over almost 30 million rows. Therefore, unless there are enough computer resources, this strategy is not a viable option.

## Dashboard

### [Tableau Dashboard](https://public.tableau.com/views/THECOVIDPLAYBOOKDASHBOARD/THECOVIDPLAYBOOKDASHBOARD?:language=en-US&:display_count=n&:origin=viz_share_link)

![dashboard_map](https://github.com/dwwatson1/coronavirus_pandemic_playbook/blob/main/Resources/dashboard_map.png)

The dashboard map presents the largest factors that were determined by running the aggregated machine learning model with ratios that contributed to the spread of COVID-19. The factors presented are:
- Age Group 50 64 No Covid Ratio
- Airport Area
- Economic Confidence Index
- Population Density
- State Land Area Sqmile
- State Policy Prevention Mandates Score
- Trump Disapproval Ratio

The [methodology](https://wallethub.com/edu/states-coronavirus-restrictions/73818) to calculate the state policy prevention mandates score is below:
- Requirement to Wear a Face Mask in Public: Double Weight (~9.30 Points)
- Travel Restrictions: Full Weight (~4.65 Points)
- Large Gatherings Restrictions: Triple Weight (~13.95 Points)
- Statewide School Restart: Double Weight (~9.30 Points)
- Reopening of Restaurants and Bars: Quadruple Weight (~18.60 Points)
   - Bars Limitations
- State Guidance on Customer Health Checks at Restaurants: Full Weight (~4.65 Points)
- Reopening of Non-Essential Businesses: Double Weight (~9.30 Points)
- Legislation on Business Immunity from COVID-19 Claims: Full Weight (~4.65 Points)
- Working from Home Requirements/Recommendations: Full Weight (~4.65 Points)
- Workplace Temperature Screening: Half Weight (~2.33 Points)
- Strictness of “Shelter in Place” Order: Triple Weight (~13.95 Points)
- Presence of Multistate Agreements to Reopen: Half Weight (~2.33 Points)
- Guidance for Assisted Living Facilities Related to COVID-19: Half Weight (~2.33 Points)
   - Staff screening
   - PPE (personal protective equipment)

Each of the states recieved different ratios dependent upon the actions they took. The more points that a state recieved the worse their COVID-19 policy protections were. Iowa had the highest score and the worst policies while Vermont had the lowest score and the best preventitive policies.

### Blueprint and Interactive Elements

One of the interactive elements we are using is the filter action. Filter actions send information between worksheets. Typically, a filter action sends information from a selected mark to another sheet showing related information. Behind the scenes, filter actions send data values from the relevant source fields as filters to the target sheet and dashboards.

For example, in a view showing the states, when a user selects a particular state name, a filter action can show all state values for all the displayed variables. 
User can select marks to see information about a specific data filed. One can also select an individual mark or multiple ones by holding down the Ctrl key (for Windows) or the Command key (macOS).

When you select marks in the view, all other marks are dimmed to draw attention to the selection. The selection is saved with the workbook. Quick data view can also be done by one of the run-on options; hovering your mouse on the charts/marks. 

We have also created a simple HTML file to show the dashboard in a dedicated webpage with another interactive element where users can download the analysis into PDF file. 

## Conclusion 

### Results

We completed 4 runs of our machine learning model. Below is an overview of the data we used in each run and their factor results:

**Data:** Aggregated state COVID-19 data with absolute values

**Feature Importance:**
* Age group 0-17 individuals
* Population Density
* 'No race' individuals
* American Indian and Alaskan Native race
* State Policy Prevention Mandate Score
 
**Data:** Aggregated state COVID-19 data with ratios

**Feature Importance:**
* Population Density
* Race: Black individuals
* State land area (sq. miles)
* Number of individuals who don't feel community recognition
* Total airports

**Data:** Aggregated state COVID-19 data with ratios, removed population density, state land area 

**Feature Importance**
* State Policy Prevention Mandate Score
* Trump disapproval
* Age group 50-64 individuals
* Airport area (land area/number of airports)
* Economic Confidence Index

**Data:** Feature engineered COVID-19 data

**Feature Importance**
* Race
* Age Group
* Population Density

### Summary

While there are lessons to be learned and perfect for our next project on the topic of COVID-19 data, however these four category of factors were the most common in our 4 runs of our model. 

1. Race
2. Age
3. Population density
4. State Mandate Policy

Let's revisit our questions from the beginning of the project.

```
1. Which social, economic, geographical, lifestyle or political factors contributed the most the spread of the disease?
2. Which category of factor contributed the most the spread of the disease?
3. Is there a connection between state policy or political leaning (i.e. mask mandate) and the spread of COVID-19 within the state
4. Do we need to account for the size of the population that didn't have COVID-19 when using a machine learning model?
```

* The longer list above answers the first question we asked at the outset of our project. 
* The shorter list here answers question #2. 
* For question #3, we wanted to find out if a state policy mandate, such as a mask mandate, or political leaning contributed to the spread of COVID-19. Trump disapproval showed up in the top 5 most important factors in run 2 but didn't show up again. State Policy Mandate Score showed up in two model runs, so there is a stronger connection to this score than political leaning. 
* For question #4, yes we did take into account the size of the population that didn't have COVID-19 so we could replicate the spread of COVID-19. We even created featured engineered data to replicate and account for those individuals in states that didn't have COVID-19. If we hadn't done this, our model would've been even less accurate and because the mode wouldn't have replicated the spread of COVID-19 correctly.

_Do we recommend rewriting the pandemic playbook?_
The short answer is yes. Given the list of most important factors, we need to update the playbook to prepare our cities better and quicker. Their emergency management systems are more equipped to deal with natural disasters or terrorist attacks rather than a pandemic. Take what happened with New York City's surge in March and April as an example of how we need to act quicker, especially in our most dense cities. Like New York City, cities generally more dense and more diverse racially and given the results from our model, these communities are more prone to the spread of COVID-19. While cities do receive federal funds, they need the most support from the states where they are located. City officials then should use these funds to hire experts to develop mitigation and quicker response plans the spread of airborne illnesses like COVID-19. 

### Lessons Learned

In the outset of the project, we decided our audience would be state lawmakers. With this in mind, we chose to focus on finding factor data tables with state columns. If we had more time to do the project over again, we would've instead chosen counties. After the first pass of our machine learning model, we learned that aggregated COVID and no COVID totals were too few data points - only 50 to measure replicate the spread of COVID-19 and determine the accuracy of our machine learning model. If we had organized our data by county, we would've ended up with 3,006 data points, far more than our original attempt.

Our aggregated model was a great way to address our question of looking at the spread of COVID in the United States but it suffered from too few observations. The exploratory model of looking at individual cases was good in theory, fixing the problem of too few observations, but suffered from random pairings in the feature engineered data, requiring an extreme amount of resources, and restricting the amount of features we can have. We can therefore suggest that if we want to create a more accurate and efficient model, the data should be aggregated by U.S. county. This fixes the faults of the aggregated model by state by allowing for more observations, and it also fixes the faults of the model by individual cases by keeping the data aggregated (removing the need for feature engineered data) and using less resources. We could also run independent analysis on each state by using their counties as observations.

### Future Projects

* **Add vaccine data.** The data we used only accounted for the spread of COVID-19 from March - December 2020. If we picked up from where we left off and looked at all of 2021, we could run our model for the spread of COVID-19 as individuals were getting vaccinated. We would keep mostly the same factors but redefine the state policy prevention mandate score to measure the days between relaxing a mask mandate or recommendation and reinstating it. For example, on July 29, DC announced it will reinstate its mask mandate indoors. We would also need to add new columns for **vaccine** or **no vaccine** and potentially study breakthrough cases of COVID-19 (vaccinated person contracts COVID-19). This is still an evolving and challenging virus. 
* **Study COVID-19 spread in regions across the world** In our analysis, we found state policy prevention mandate score as the top factor for determining the spread of COVID-19. Would this be similar in states or regions in Mexico or Australia, for example. We would like to explore similar factors in countries with different governemtn COVID-19 responses. Australia had one of the most severe travel restrictions for entering and leaving the country but no intial lockdown or mask mandate or recommendation.  


